{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9443b0d6",
   "metadata": {},
   "source": [
    "PyTorch is a framework for creating machine learning models, including deep neural networks (DNNs). In this example, we'll use PyTorch to create a simple neural network that classifies penguins into species based on the length and depth of their culmen (bill), their flipper length, and their body mass."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40282dac",
   "metadata": {},
   "source": [
    "Let's get started:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f026713",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aef59e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the dataset\n",
    "penguins = pd.read_csv('https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/ml-basics/penguins.csv').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16ba782a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Learning models work best when features are on similar scales\n",
    "# In a real solution, we'd implement some custom normalization for each feature, but to keep things simple\n",
    "# we'll just rescale the FlipperLength and BodyMass so they're on a similar scale to the bill measurements\n",
    "penguins['FlipperLength'] = penguins['FlipperLength']/10\n",
    "penguins['BodyMass'] = penguins['BodyMass']/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11e4fa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset is too small to be useful for deep learning\n",
    "# So we'll oversample it to increase its size\n",
    "penguins = pd.concat([penguins, penguins])\n",
    "penguins = pd.concat([penguins, penguins])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f3ff79",
   "metadata": {},
   "source": [
    "The **Species** column is the label our model will predict. Each label value represents a class of penguin species, encoded as 0, 1, or 2. The following code shows the actual species to which these class labels corrrespond."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2a7b1d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CulmenLength</th>\n",
       "      <th>CulmenDepth</th>\n",
       "      <th>FlipperLength</th>\n",
       "      <th>BodyMass</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>39.2</td>\n",
       "      <td>19.6</td>\n",
       "      <td>19.5</td>\n",
       "      <td>46.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>50.5</td>\n",
       "      <td>19.6</td>\n",
       "      <td>20.1</td>\n",
       "      <td>40.50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>49.2</td>\n",
       "      <td>15.2</td>\n",
       "      <td>22.1</td>\n",
       "      <td>63.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>36.2</td>\n",
       "      <td>17.3</td>\n",
       "      <td>18.7</td>\n",
       "      <td>33.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>33.1</td>\n",
       "      <td>16.1</td>\n",
       "      <td>17.8</td>\n",
       "      <td>29.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>37.8</td>\n",
       "      <td>17.1</td>\n",
       "      <td>18.6</td>\n",
       "      <td>33.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>45.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>50.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>49.0</td>\n",
       "      <td>16.1</td>\n",
       "      <td>21.6</td>\n",
       "      <td>55.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>39.7</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.4</td>\n",
       "      <td>35.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>37.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>18.5</td>\n",
       "      <td>34.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     CulmenLength  CulmenDepth  FlipperLength  BodyMass  Species\n",
       "7            39.2         19.6           19.5     46.75        0\n",
       "291          50.5         19.6           20.1     40.50        2\n",
       "169          49.2         15.2           22.1     63.00        1\n",
       "94           36.2         17.3           18.7     33.00        0\n",
       "98           33.1         16.1           17.8     29.00        0\n",
       "10           37.8         17.1           18.6     33.00        0\n",
       "209          45.5         15.0           22.0     50.00        1\n",
       "163          49.0         16.1           21.6     55.50        1\n",
       "105          39.7         18.9           18.4     35.50        0\n",
       "138          37.0         16.5           18.5     34.00        0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display a random sample of 10 observations\n",
    "sample = penguins.sample(10)\n",
    "sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9f2fe78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CulmenLength' 'CulmenDepth' 'FlipperLength' 'BodyMass' 'Species'] SpeciesName\n",
      "[ 36.4 17.0 19.5 33.25 0 ] Adelie\n",
      "[ 40.9 16.8 19.1 37.0 0 ] Adelie\n",
      "[ 40.9 13.7 21.4 46.5 1 ] Gentoo\n",
      "[ 37.8 18.3 17.4 34.0 0 ] Adelie\n",
      "[ 51.1 16.5 22.5 52.5 1 ] Gentoo\n",
      "[ 36.8 18.5 19.3 35.0 0 ] Adelie\n",
      "[ 50.0 15.9 22.4 53.5 1 ] Gentoo\n",
      "[ 40.1 18.9 18.8 43.0 0 ] Adelie\n",
      "[ 39.6 20.7 19.1 39.0 0 ] Adelie\n",
      "[ 36.0 17.8 19.5 34.5 0 ] Adelie\n"
     ]
    }
   ],
   "source": [
    "penguin_classes = ['Adelie', 'Gentoo', 'Chinstrap']\n",
    "print(sample.columns[0:5].values, 'SpeciesName')\n",
    "for index, row in penguins.sample(10).iterrows():\n",
    "    print('[',row[0], row[1], row[2],row[3], int(row[4]), ']',penguin_classes[int(row[-1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75567d4d",
   "metadata": {},
   "source": [
    "Split the data into test and train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8b874b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set: 957, Test Set: 411 \n",
      "\n",
      "Sample of features and labels:\n",
      "[51.1 16.5 22.5 52.5] 1 (Gentoo)\n",
      "[50.7 19.7 20.3 40.5] 2 (Chinstrap)\n",
      "[49.5 16.2 22.9 58. ] 1 (Gentoo)\n",
      "[39.3 20.6 19.  36.5] 0 (Adelie)\n",
      "[42.5 20.7 19.7 45. ] 0 (Adelie)\n",
      "[50.  15.3 22.  55.5] 1 (Gentoo)\n",
      "[50.2  18.7  19.8  37.75] 2 (Chinstrap)\n",
      "[50.7 19.7 20.3 40.5] 2 (Chinstrap)\n",
      "[49.1  14.5  21.2  46.25] 1 (Gentoo)\n",
      "[43.2 16.6 18.7 29. ] 2 (Chinstrap)\n",
      "[38.8  17.6  19.1  32.75] 0 (Adelie)\n",
      "[37.8 17.1 18.6 33. ] 0 (Adelie)\n",
      "[45.8 14.2 21.9 47. ] 1 (Gentoo)\n",
      "[43.8 13.9 20.8 43. ] 1 (Gentoo)\n",
      "[36.  17.1 18.7 37. ] 0 (Adelie)\n",
      "[43.3 13.4 20.9 44. ] 1 (Gentoo)\n",
      "[36.  18.5 18.6 31. ] 0 (Adelie)\n",
      "[41.1  19.   18.2  34.25] 0 (Adelie)\n",
      "[33.1 16.1 17.8 29. ] 0 (Adelie)\n",
      "[40.9 13.7 21.4 46.5] 1 (Gentoo)\n",
      "[45.2 17.8 19.8 39.5] 2 (Chinstrap)\n",
      "[48.4 14.6 21.3 58.5] 1 (Gentoo)\n",
      "[43.6 13.9 21.7 49. ] 1 (Gentoo)\n",
      "[38.5  17.9  19.   33.25] 0 (Adelie)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features = ['CulmenLength','CulmenDepth','FlipperLength','BodyMass']\n",
    "label = 'Species'\n",
    "   \n",
    "# Split data 70%-30% into training set and test set\n",
    "x_train, x_test, y_train, y_test = train_test_split(penguins[features].values,\n",
    "                                                    penguins[label].values,\n",
    "                                                    test_size=0.30,\n",
    "                                                    random_state=0)\n",
    "\n",
    "print ('Training Set: %d, Test Set: %d \\n' % (len(x_train), len(x_test)))\n",
    "print(\"Sample of features and labels:\")\n",
    "\n",
    "# Take a look at the first 25 training features and corresponding labels\n",
    "for n in range(0,24):\n",
    "    print(x_train[n], y_train[n], '(' + penguin_classes[y_train[n]] + ')')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285512ee",
   "metadata": {},
   "source": [
    "Importing necessary libraries form PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a64fa6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a535737d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1e670d36790>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set random seed for reproducability\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b1d4a9",
   "metadata": {},
   "source": [
    "### Prepare the data for PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e340c05",
   "metadata": {},
   "source": [
    "PyTorch makes use of data loaders to load training and validation data in batches. We've already loaded the data into numpy arrays, but we need to wrap those in PyTorch datasets (in which the data is converted to PyTorch tensor objects) and create loaders to read batches from those datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c5ed843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset and loader for the training data and labels\n",
    "train_x = torch.Tensor(x_train).float()\n",
    "train_y = torch.Tensor(y_train).long()\n",
    "train_ds = td.TensorDataset(train_x,train_y)\n",
    "train_loader = td.DataLoader(train_ds, batch_size=20,\n",
    "    shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83eef727",
   "metadata": {},
   "source": [
    "***torch.tensor()*** is used to build a multi-dimensional matrix containing elements of a single data type.\n",
    "\n",
    "***td.TensorDataset*** is dataset wrapping tensors. Each sample can be retrieved by indexing tensors along the first dimension.The Dataset class is an abstract class that is used to define new types of (customs) datasets. Instead, the TensorDataset is a ready to use class to represent your data as list of tensors.\n",
    "\n",
    "***td.DataLoader*** combines a dataset and a sampler, and provides an iterable over the given dataset.\n",
    "\n",
    "***batch_size*** argument helps hus to specify how many samples per batch to load. By default batch_size = 1.\n",
    "\n",
    "***shuffle*** - set to True to have the data reshuffled at every epoch. But, by default, it's value is False.\n",
    "\n",
    "***num_workers*** how many subprocesses to use for data loading. 0 means that the data will be loaded in the main process. Default is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95a23e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to load data\n"
     ]
    }
   ],
   "source": [
    "# Create a dataset and loader for the test data and labels\n",
    "test_x = torch.Tensor(x_test).float()\n",
    "test_y = torch.Tensor(y_test).long()\n",
    "test_ds = td.TensorDataset(test_x,test_y)\n",
    "test_loader = td.DataLoader(test_ds, batch_size=20,\n",
    "    shuffle=False, num_workers=1)\n",
    "print('Ready to load data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c36a5e",
   "metadata": {},
   "source": [
    "Now we're ready to define our neural network. In this case, we'll create a network that consists of 3 fully-connected layers:\n",
    "* An input layer that receives an input value for each feature (in this case, the four penguin measurements) and applies a *ReLU* activation function.\n",
    "* A hidden layer that receives ten inputs and applies a *ReLU* activation function.\n",
    "* An output layer that generates a non-negative numeric output for each penguin species (which a loss function will translate into classification probabilities for each of the three possible penguin species)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fba74fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PenguinNet(\n",
      "  (fc1): Linear(in_features=4, out_features=10, bias=True)\n",
      "  (fc2): Linear(in_features=10, out_features=10, bias=True)\n",
      "  (fc3): Linear(in_features=10, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Number of hidden layer nodes\n",
    "hl = 10\n",
    "\n",
    "# Define the neural network\n",
    "class PenguinNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PenguinNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(len(features), hl)\n",
    "        self.fc2 = nn.Linear(hl, hl)\n",
    "        self.fc3 = nn.Linear(hl, len(penguin_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "# Create a model instance from the network\n",
    "model = PenguinNet()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e84b2e8",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98608448",
   "metadata": {},
   "source": [
    "To train the model, we need to repeatedly feed the training values forward through the network, use a loss function to calculate the loss, use an optimizer to backpropagate the weight and bias value adjustments, and validate the model using the test data we withheld.\n",
    "\n",
    "To do this, we'll create a function to train and optimize the model, and function to test the model. Then we'll call these functions iteratively over 50 epochs, logging the loss and accuracy statistics for each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34d9ee8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Training set: Average loss: 1.118814\n",
      "Validation set: Average loss: 1.023595, Accuracy: 148/411 (36%)\n",
      "\n",
      "Epoch: 2\n",
      "Training set: Average loss: 1.010274\n",
      "Validation set: Average loss: 0.983460, Accuracy: 163/411 (40%)\n",
      "\n",
      "Epoch: 3\n",
      "Training set: Average loss: 0.965314\n",
      "Validation set: Average loss: 0.934165, Accuracy: 191/411 (46%)\n",
      "\n",
      "Epoch: 4\n",
      "Training set: Average loss: 0.911513\n",
      "Validation set: Average loss: 0.867269, Accuracy: 250/411 (61%)\n",
      "\n",
      "Epoch: 5\n",
      "Training set: Average loss: 0.817720\n",
      "Validation set: Average loss: 0.742112, Accuracy: 272/411 (66%)\n",
      "\n",
      "Epoch: 6\n",
      "Training set: Average loss: 0.733329\n",
      "Validation set: Average loss: 0.691639, Accuracy: 302/411 (73%)\n",
      "\n",
      "Epoch: 7\n",
      "Training set: Average loss: 0.696301\n",
      "Validation set: Average loss: 0.661350, Accuracy: 312/411 (76%)\n",
      "\n",
      "Epoch: 8\n",
      "Training set: Average loss: 0.671731\n",
      "Validation set: Average loss: 0.640087, Accuracy: 327/411 (80%)\n",
      "\n",
      "Epoch: 9\n",
      "Training set: Average loss: 0.653092\n",
      "Validation set: Average loss: 0.624311, Accuracy: 338/411 (82%)\n",
      "\n",
      "Epoch: 10\n",
      "Training set: Average loss: 0.638097\n",
      "Validation set: Average loss: 0.610605, Accuracy: 345/411 (84%)\n",
      "\n",
      "Epoch: 11\n",
      "Training set: Average loss: 0.625696\n",
      "Validation set: Average loss: 0.598022, Accuracy: 345/411 (84%)\n",
      "\n",
      "Epoch: 12\n",
      "Training set: Average loss: 0.614685\n",
      "Validation set: Average loss: 0.588183, Accuracy: 353/411 (86%)\n",
      "\n",
      "Epoch: 13\n",
      "Training set: Average loss: 0.605506\n",
      "Validation set: Average loss: 0.578678, Accuracy: 358/411 (87%)\n",
      "\n",
      "Epoch: 14\n",
      "Training set: Average loss: 0.597361\n",
      "Validation set: Average loss: 0.569911, Accuracy: 361/411 (88%)\n",
      "\n",
      "Epoch: 15\n",
      "Training set: Average loss: 0.590228\n",
      "Validation set: Average loss: 0.562248, Accuracy: 361/411 (88%)\n",
      "\n",
      "Epoch: 16\n",
      "Training set: Average loss: 0.583250\n",
      "Validation set: Average loss: 0.556146, Accuracy: 372/411 (91%)\n",
      "\n",
      "Epoch: 17\n",
      "Training set: Average loss: 0.576846\n",
      "Validation set: Average loss: 0.549725, Accuracy: 375/411 (91%)\n",
      "\n",
      "Epoch: 18\n",
      "Training set: Average loss: 0.571098\n",
      "Validation set: Average loss: 0.544390, Accuracy: 382/411 (93%)\n",
      "\n",
      "Epoch: 19\n",
      "Training set: Average loss: 0.565975\n",
      "Validation set: Average loss: 0.540335, Accuracy: 384/411 (93%)\n",
      "\n",
      "Epoch: 20\n",
      "Training set: Average loss: 0.561476\n",
      "Validation set: Average loss: 0.536972, Accuracy: 389/411 (95%)\n",
      "\n",
      "Epoch: 21\n",
      "Training set: Average loss: 0.557517\n",
      "Validation set: Average loss: 0.532509, Accuracy: 390/411 (95%)\n",
      "\n",
      "Epoch: 22\n",
      "Training set: Average loss: 0.553931\n",
      "Validation set: Average loss: 0.529417, Accuracy: 396/411 (96%)\n",
      "\n",
      "Epoch: 23\n",
      "Training set: Average loss: 0.550773\n",
      "Validation set: Average loss: 0.528216, Accuracy: 397/411 (97%)\n",
      "\n",
      "Epoch: 24\n",
      "Training set: Average loss: 0.547976\n",
      "Validation set: Average loss: 0.523656, Accuracy: 397/411 (97%)\n",
      "\n",
      "Epoch: 25\n",
      "Training set: Average loss: 0.545466\n",
      "Validation set: Average loss: 0.521025, Accuracy: 397/411 (97%)\n",
      "\n",
      "Epoch: 26\n",
      "Training set: Average loss: 0.543647\n",
      "Validation set: Average loss: 0.519855, Accuracy: 400/411 (97%)\n",
      "\n",
      "Epoch: 27\n",
      "Training set: Average loss: 0.542047\n",
      "Validation set: Average loss: 0.517385, Accuracy: 398/411 (97%)\n",
      "\n",
      "Epoch: 28\n",
      "Training set: Average loss: 0.540234\n",
      "Validation set: Average loss: 0.515388, Accuracy: 400/411 (97%)\n",
      "\n",
      "Epoch: 29\n",
      "Training set: Average loss: 0.538976\n",
      "Validation set: Average loss: 0.512899, Accuracy: 401/411 (98%)\n",
      "\n",
      "Epoch: 30\n",
      "Training set: Average loss: 0.537303\n",
      "Validation set: Average loss: 0.512066, Accuracy: 404/411 (98%)\n",
      "\n",
      "Epoch: 31\n",
      "Training set: Average loss: 0.536062\n",
      "Validation set: Average loss: 0.511284, Accuracy: 404/411 (98%)\n",
      "\n",
      "Epoch: 32\n",
      "Training set: Average loss: 0.534580\n",
      "Validation set: Average loss: 0.508444, Accuracy: 404/411 (98%)\n",
      "\n",
      "Epoch: 33\n",
      "Training set: Average loss: 0.533200\n",
      "Validation set: Average loss: 0.507806, Accuracy: 404/411 (98%)\n",
      "\n",
      "Epoch: 34\n",
      "Training set: Average loss: 0.532376\n",
      "Validation set: Average loss: 0.505557, Accuracy: 404/411 (98%)\n",
      "\n",
      "Epoch: 35\n",
      "Training set: Average loss: 0.531220\n",
      "Validation set: Average loss: 0.503028, Accuracy: 404/411 (98%)\n",
      "\n",
      "Epoch: 36\n",
      "Training set: Average loss: 0.529759\n",
      "Validation set: Average loss: 0.502396, Accuracy: 404/411 (98%)\n",
      "\n",
      "Epoch: 37\n",
      "Training set: Average loss: 0.528576\n",
      "Validation set: Average loss: 0.501712, Accuracy: 404/411 (98%)\n",
      "\n",
      "Epoch: 38\n",
      "Training set: Average loss: 0.527694\n",
      "Validation set: Average loss: 0.499238, Accuracy: 404/411 (98%)\n",
      "\n",
      "Epoch: 39\n",
      "Training set: Average loss: 0.526515\n",
      "Validation set: Average loss: 0.498586, Accuracy: 404/411 (98%)\n",
      "\n",
      "Epoch: 40\n",
      "Training set: Average loss: 0.525752\n",
      "Validation set: Average loss: 0.496938, Accuracy: 404/411 (98%)\n",
      "\n",
      "Epoch: 41\n",
      "Training set: Average loss: 0.524745\n",
      "Validation set: Average loss: 0.496314, Accuracy: 405/411 (99%)\n",
      "\n",
      "Epoch: 42\n",
      "Training set: Average loss: 0.524034\n",
      "Validation set: Average loss: 0.494481, Accuracy: 404/411 (98%)\n",
      "\n",
      "Epoch: 43\n",
      "Training set: Average loss: 0.523150\n",
      "Validation set: Average loss: 0.492949, Accuracy: 404/411 (98%)\n",
      "\n",
      "Epoch: 44\n",
      "Training set: Average loss: 0.522167\n",
      "Validation set: Average loss: 0.492328, Accuracy: 404/411 (98%)\n",
      "\n",
      "Epoch: 45\n",
      "Training set: Average loss: 0.521537\n",
      "Validation set: Average loss: 0.490820, Accuracy: 401/411 (98%)\n",
      "\n",
      "Epoch: 46\n",
      "Training set: Average loss: 0.521010\n",
      "Validation set: Average loss: 0.489736, Accuracy: 401/411 (98%)\n",
      "\n",
      "Epoch: 47\n",
      "Training set: Average loss: 0.520252\n",
      "Validation set: Average loss: 0.489686, Accuracy: 404/411 (98%)\n",
      "\n",
      "Epoch: 48\n",
      "Training set: Average loss: 0.519929\n",
      "Validation set: Average loss: 0.488752, Accuracy: 401/411 (98%)\n",
      "\n",
      "Epoch: 49\n",
      "Training set: Average loss: 0.519249\n",
      "Validation set: Average loss: 0.488609, Accuracy: 405/411 (99%)\n",
      "\n",
      "Epoch: 50\n",
      "Training set: Average loss: 0.518899\n",
      "Validation set: Average loss: 0.487255, Accuracy: 401/411 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train(model, data_loader, optimizer):\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    \n",
    "    for batch, tensor in enumerate(data_loader):\n",
    "        data, target = tensor\n",
    "        #feedforward\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = loss_criteria(out, target)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # backpropagate\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    #Return average loss\n",
    "    avg_loss = train_loss / (batch+1)\n",
    "    print('Training set: Average loss: {:.6f}'.format(avg_loss))\n",
    "    return avg_loss\n",
    "           \n",
    "            \n",
    "def test(model, data_loader):\n",
    "    # Switch the model to evaluation mode (so we don't backpropagate)\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        batch_count = 0\n",
    "        for batch, tensor in enumerate(data_loader):\n",
    "            batch_count += 1\n",
    "            data, target = tensor\n",
    "            # Get the predictions\n",
    "            out = model(data)\n",
    "\n",
    "            # calculate the loss\n",
    "            test_loss += loss_criteria(out, target).item()\n",
    "\n",
    "            # Calculate the accuracy\n",
    "            _, predicted = torch.max(out.data, 1)\n",
    "            correct += torch.sum(target==predicted).item()\n",
    "            \n",
    "    # Calculate the average loss and total accuracy for this epoch\n",
    "    avg_loss = test_loss/batch_count\n",
    "    print('Validation set: Average loss: {:.6f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        avg_loss, correct, len(data_loader.dataset),\n",
    "        100. * correct / len(data_loader.dataset)))\n",
    "    \n",
    "    # return average loss for the epoch\n",
    "    return avg_loss\n",
    "\n",
    "# Specify the loss criteria (we'll use CrossEntropyLoss for multi-class classification)\n",
    "loss_criteria = nn.CrossEntropyLoss()\n",
    "\n",
    "# Use an \"Adam\" optimizer to adjust weights\n",
    "# (see https://pytorch.org/docs/stable/optim.html#algorithms for details of supported algorithms)\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# We'll track metrics for each epoch in these arrays\n",
    "epoch_nums = []\n",
    "training_loss = []\n",
    "validation_loss = []\n",
    "\n",
    "# Train over 50 epochs\n",
    "epochs = 50\n",
    "for epoch in range(1, epochs + 1):\n",
    "\n",
    "    # print the epoch number\n",
    "    print('Epoch: {}'.format(epoch))\n",
    "    \n",
    "    # Feed training data into the model to optimize the weights\n",
    "    train_loss = train(model, train_loader, optimizer)\n",
    "    \n",
    "    # Feed the test data into the model to check its performance\n",
    "    test_loss = test(model, test_loader)\n",
    "    \n",
    "    # Log the metrics for this epoch\n",
    "    epoch_nums.append(epoch)\n",
    "    training_loss.append(train_loss)\n",
    "    validation_loss.append(test_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae7840d",
   "metadata": {},
   "source": [
    " let's try to understand what's happening:\n",
    "\n",
    "1. In each *epoch*, the full set of training data is passed forward through the network. There are four features for each observation, and four corresponding nodes in the input layer - so the features for each observation are passed as a vector of four values to that layer. However, for efficiency, the feature vectors are grouped into batches; so actually a matrix of multiple feature vectors is fed in each time.\n",
    "2. The matrix of feature values is processed by a function that performs a weighted sum using initialized weights and bias values. The result of this function is then processed by the activation function for the input layer to constrain the values passed to the nodes in the next layer.\n",
    "3. The weighted sum and activation functions are repeated in each layer. Note that the functions operate on vectors and matrices rather than individual scalar values. In other words, the forward pass is essentially a series of nested linear algebra functions. This is the reason data scientists prefer to use computers with graphical processing units (GPUs), since these are optimized for matrix and vector calculations.\n",
    "4. In the final layer of the network, the output vectors contain a calculated value for each possible class (in this case, classes 0, 1, and 2). This vector is processed by a *loss function* that converts these values to probabilities and determines how far they are from the expected values based on the actual classes - so for example, suppose the output for a Gentoo penguin (class 1) observation is \\[0.3, 0.4, 0.3\\]. The correct prediction would be \\[0.0, 1.0, 0.0\\], so the variance between the predicted and actual values (how far away each predicted value is from what it should be) is \\[0.3, 0.6, 0.3\\]. This variance is aggregated for each batch and maintained as a running aggregate to calculate the overall level of error (*loss*) incurred by the training data for the epoch. \n",
    "5. At the end of each epoch, the validation data is passed through the network, and its loss and accuracy (proportion of correct predictions based on the highest probability value in the output vector) are also calculated. It's important to do this because it enables us to compare the performance of the model using data on which it was not trained, helping us determine if it will generalize well for new data or if it's *overfitted* to the training data.\n",
    "6. After all the data has been passed forward through the network, the output of the loss function for the *training* data (but <u>not</u> the *validation* data) is passed to the opimizer. The precise details of how the optimizer processes the loss vary depending on the specific optimization algorithm being used; but fundamentally you can think of the entire network, from the input layer to the loss function as being one big nested (*composite*) function. The optimizer applies some differential calculus to calculate *partial derivatives* for the function with respect to each weight and bias value that was used in the network. It's possible to do this efficiently for a nested function due to something called the *chain rule*, which enables you to determine the derivative of a composite function from the derivatives of its inner function and outer functions. You don't really need to worry about the details of the math here (the optimizer does it for you), but the end result is that the partial derivatives tell us about the slope (or *gradient*) of the loss function with respect to each weight and bias value - in other words, we can determine whether to increase or decrease the weight and bias values in order to decrease the loss.\n",
    "7. Having determined in which direction to adjust the weights and biases, the optimizer uses the *learning rate* to determine by how much to adjust them; and then works backwards through the network in a process called *backpropagation* to assign new values to the weights and biases in each layer.\n",
    "8. Now the next epoch repeats the whole training, validation, and backpropagation process starting with the revised weights and biases from the previous epoch - which hopefully will result in a lower level of loss.\n",
    "9. The process continues like this for 50 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea41a4d",
   "metadata": {},
   "source": [
    "## Review training and validation loss\n",
    "\n",
    "After training is complete, we can examine the loss metrics we recorded while training and validating the model. We're really looking for two things:\n",
    "* The loss should reduce with each epoch, showing that the model is learning the right weights and biases to predict the correct labels.\n",
    "* The training loss and validation loss should follow a similar trend, showing that the model is not overfitting to the training data.\n",
    "\n",
    "Let's plot the loss metrics and see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6782a0e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(epoch_nums, training_loss)\n",
    "plt.plot(epoch_nums, validation_loss)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['training', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b02e2bc",
   "metadata": {},
   "source": [
    "## View the learned weights and biases\n",
    "\n",
    "The trained model consists of the final weights and biases that were determined by the optimizer during training. Based on our network model we should expect the following values for each layer:\n",
    "* Layer 1: There are four input values going to ten output nodes, so there should be 10 x 4 weights and 10 bias values.\n",
    "* Layer 2: There are ten input values going to ten output nodes, so there should be 10 x 10 weights and 10 bias values.\n",
    "* Layer 3: There are ten input values going to three output nodes, so there should be 3 x 10 weights and 3 bias values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb2cce39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.weight \n",
      " [[-0.00374341  0.2682218  -0.41152257 -0.3679695 ]\n",
      " [-0.17916065 -0.08960588  0.11843111  0.5180273 ]\n",
      " [-0.04437202  0.13230628 -0.15110654 -0.09828269]\n",
      " [-0.47767425 -0.33114105 -0.20611155  0.01852179]\n",
      " [ 0.22086564  0.57115096 -0.4008633  -0.1869742 ]\n",
      " [ 0.31580445  0.247769   -0.20200182  0.398905  ]\n",
      " [-0.08059168  0.05290705  0.4527381  -0.46383518]\n",
      " [-0.3545517  -0.15797205 -0.23337851  0.39141223]\n",
      " [-0.32408983 -0.23016644 -0.34932023 -0.4682805 ]\n",
      " [-0.4734976   0.80028427  0.3018039   0.15444127]]\n",
      "fc1.bias \n",
      " [ 0.02629578 -0.20744476  0.08459234 -0.46684736 -0.355858   -0.45410085\n",
      "  0.31546897  0.25728968 -0.22174752  0.24439499]\n",
      "fc2.weight \n",
      " [[ 0.20224687  0.3143725   0.12550515  0.04272011  0.21202639 -0.18619564\n",
      "   0.05892715 -0.24517313 -0.21917307 -0.16335806]\n",
      " [ 0.14308453  0.08098815 -0.18731831  0.09553465  0.74755704 -0.0117083\n",
      "   0.01207405  0.03671877  0.19618031  0.71772873]\n",
      " [-0.24369258 -0.09592997  0.12428063  0.2620103   0.4403401   0.3276189\n",
      "   0.06293392 -0.24256472  0.02909058 -0.64388627]\n",
      " [-0.29470977  0.43695053  0.2404469  -0.31544605 -0.65187365 -0.03367815\n",
      "  -0.05203882 -0.09720274  0.12160733 -0.44795007]\n",
      " [ 0.11592636  0.15991893  0.22637847  0.11824107 -0.31298175 -0.20513597\n",
      "   0.15789726  0.0661869  -0.24668422 -0.1820901 ]\n",
      " [ 0.29749104  0.3398366  -0.13788326 -0.07958971 -1.0037646   0.04011771\n",
      "  -0.23813814 -0.21048176 -0.01742402 -0.21410412]\n",
      " [-0.12950484  0.18764248 -0.19243696  0.2869356   0.21671084 -0.26666948\n",
      "  -0.07870413  0.01426902  0.04613796  0.07500109]\n",
      " [ 0.12409672  0.01894209 -0.15429662  0.1496355  -0.30334112 -0.1874303\n",
      "  -0.07916126 -0.15403877 -0.11062703 -0.25918713]\n",
      " [-0.06726643  0.16598706 -0.20601156 -0.01622862 -0.10633218 -0.07815903\n",
      "   0.00878868  0.00450952  0.06399861  0.46543372]\n",
      " [ 0.29954556  0.20082232  0.3002309  -0.02287012 -0.2840742  -0.14991638\n",
      "   0.21532115 -0.00204995 -0.15717986 -0.24232906]]\n",
      "fc2.bias \n",
      " [-0.2959424  -0.09140173 -0.24091293  0.11557583  0.17096573 -0.32246786\n",
      "  0.19725719 -0.24745122  0.03521881 -0.1282217 ]\n",
      "fc3.weight \n",
      " [[-0.06091028 -0.06208903 -0.28376698 -0.27304304 -0.04948315  0.0040895\n",
      "  -0.14365433  0.11912274 -0.28462344 -0.02134135]\n",
      " [ 0.27809682 -0.41300258  0.273101    0.7309681  -0.2853832   0.65255636\n",
      "  -0.03649095 -0.14116624 -0.0045454  -0.25554216]\n",
      " [ 0.03393281 -0.1929086   0.71934223 -0.3108009   0.15194914 -0.33142668\n",
      "  -0.07604478 -0.06650442 -1.1165305   0.17134616]]\n",
      "fc3.bias \n",
      " [ 0.25107792  0.10447471 -0.24180879]\n"
     ]
    }
   ],
   "source": [
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\n\", model.state_dict()[param_tensor].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bb66cb",
   "metadata": {},
   "source": [
    "## Evaluate model performance\n",
    "\n",
    "So, is the model any good? The raw accuracy reported from the validation data would seem to indicate that it predicts pretty well; but it's typically useful to dig a little deeper and compare the predictions for each possible class. A common way to visualize the performance of a classification model is to create a *confusion matrix* that shows a crosstab of correct and incorrect predictions for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3afe7f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Pytorch doesn't have a built-in confusion matrix metric, so we'll use SciKit-Learn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Set the model to evaluate mode\n",
    "model.eval()\n",
    "\n",
    "# Get predictions for the test data\n",
    "x = torch.Tensor(x_test).float()\n",
    "_, predicted = torch.max(model(x).data, 1)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "cm = confusion_matrix(y_test, predicted.numpy())\n",
    "plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(penguin_classes))\n",
    "plt.xticks(tick_marks, penguin_classes, rotation=45)\n",
    "plt.yticks(tick_marks, penguin_classes)\n",
    "plt.xlabel(\"Predicted Species\")\n",
    "plt.ylabel(\"Actual Species\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780250fd",
   "metadata": {},
   "source": [
    "The confusion matrix should show a strong diagonal line indicating that there are more correct than incorrect predictions for each class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da8574b",
   "metadata": {},
   "source": [
    "## Save the trained model\n",
    "Now that we have a model we believe is reasonably accurate, we can save its trained weights for use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439237a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model weights\n",
    "model_file = 'models/penguin_classifier.pt'\n",
    "torch.save(model.state_dict(), model_file)\n",
    "del model\n",
    "print('model saved as', model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73dac0ee",
   "metadata": {},
   "source": [
    "## Use the trained model\n",
    "\n",
    "When we have a new penguin observation, we can use the model to predict the species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baed198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New penguin features\n",
    "x_new = [[50.4,15.3,20,50]]\n",
    "print ('New sample: {}'.format(x_new))\n",
    "\n",
    "# Create a new model class and load weights\n",
    "model = PenguinNet()\n",
    "model.load_state_dict(torch.load(model_file))\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Get a prediction for the new data sample\n",
    "x = torch.Tensor(x_new).float()\n",
    "_, predicted = torch.max(model(x).data, 1)\n",
    "\n",
    "print('Prediction:',penguin_classes[predicted.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8a6788",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
