{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8953d4f",
   "metadata": {},
   "source": [
    "Here, we are going to use MNIST database.\n",
    "\n",
    "The <strong>MNIST database</strong>, short for Modified National Institute of Standards and Technology database, is a large database of handwritten digits that is commonly used for training various image processing systems. The database is also widely used for training and testing in the field of machine learning.\n",
    "\n",
    "The MNIST database contains 60,000 training images and 10,000 testing images of digits written by high school students and employees of the United States Census Bureau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f1f6654",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc232b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48db5c16",
   "metadata": {},
   "source": [
    "When working with *convolutional neural networks* in particular, we will need additional packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf6739ae",
   "metadata": {},
   "outputs": [],
   "source": [
    " # to add convolutional layers\n",
    "from keras.layers.convolutional import Conv2D\n",
    "\n",
    " # to add pooling layers\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "\n",
    " # to flatten data for fully connected layers\n",
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6033f4e",
   "metadata": {},
   "source": [
    "***1. Convolution kernel*** is a filter that is used to extract the features from the images.\\\n",
    "***2. keras.layers.convolutional.Conv2D*** creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs.\\\n",
    "***3. PyTorch Tensor*** is basically the same as a numpy array: it does not know anything about deep learning or computational graphs or gradients, and is just a generic n-dimensional array to be used for arbitrary numeric computation.\\\n",
    "***4. Downsampling***  means reducing the number of parameters ensuring higher computational speeds. It also makes output tolerant to small transitional changes in the input.\\\n",
    "***5. keras.layers.convolutional.MaxPooling2D*** downsamples the input along its spatial dimensions (height and width) by taking the maximum value over an input window.\\\n",
    "***6. Flattening*** is converting the data into a 1-dimensional array for inputting it to the next layer.\\\n",
    "***7. keras.layers.Flatten*** flattens the input without affecting the batch size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f755990",
   "metadata": {},
   "source": [
    "The Keras library conveniently includes the MNIST dataset as part of its API.\\\n",
    "So, let's load the MNIST dataset from the Keras library. The dataset is readily divided into a training set and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0af55793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# load the data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb0a6f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8f2669",
   "metadata": {},
   "source": [
    "Now, let's convert the target variable into binary categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0415f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "num_classes = y_test.shape[1] # number of categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b205df80",
   "metadata": {},
   "source": [
    "\n",
    "***1. to_categorical*** Using this, a numpy array (or) a vector which has integers that represent different categories, can be converted into a numpy array (or) a matrix which has binary values and has columns equal to the number of categories in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfc6f807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7276cc10",
   "metadata": {},
   "source": [
    "Next, let's define a function that creates our model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627abd54",
   "metadata": {},
   "source": [
    "### Convolutional NN with one set of convolutional and pooling layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca31ed69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_model():\n",
    "    \n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (5, 5), strides=(1, 1), activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    # compile model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfdafac",
   "metadata": {},
   "source": [
    "***1. Sequential()*** groups a linear stack of layers into a ***tf.keras.Model***.\n",
    "It provides training and inference features on this model.\\\n",
    "***2. .add()*** method is used tpo add layers to our NN model.\\\n",
    "***3. Conv2D(16, (5, 5), strides=(1, 1), activation='relu', input_shape=(28, 28, 1)) :*** Insise Conv2D(),\n",
    "\n",
    "\n",
    "\n",
    "$\\;\\;\\;\\;\\;\\;$**a.** *parameter* ***16*** is known as *filter* and it's value is the number of output filters in convolution.\\\n",
    "$\\;\\;\\;\\;\\;\\;$**b.** *parameter* ***(5, 5)*** is the kernel size which is an integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution window. Can be a $\\;\\;\\;\\;\\;\\;$$\\;\\;\\;$single integer to specify the same value for all spatial dimensions.\\\n",
    "$\\;\\;\\;\\;\\;\\;$**c.** *parameter* ***strides = (1, 1)*** specifies the strides of the convolution along with height ans width. A *Stride* is a component of convolutional neural networks $\\;\\;\\;\\;\\;\\;$$\\;\\;\\;$tuned for the compression of images and video data.\\\n",
    "$\\;\\;\\;\\;\\;\\;$**d.** *parameter* ***activation = 'relu'*** means that the *Rectified Linear Unit* will be used as activation function.\\\n",
    "$\\;\\;\\;\\;\\;\\;$**e.** *parameter* ***input_shape = (28, 28, 1)*** is the dimension of input we provide and this is only used while creating the first layer.\n",
    "\n",
    "***4. MaxPooling2D(pool_size=(2, 2), strides=(2, 2)) :***  Inside MaxPooling2D(),\n",
    "\n",
    "$\\;\\;\\;\\;\\;\\;$**a.** *parameter* ***pool_size = (2, 2)*** is used to specify the size of input window.\\\n",
    "$\\;\\;\\;\\;\\;\\;$**b.** *parameter* ***strides = (2, 2)*** is used to shift window in each dimension.\\\n",
    "\n",
    "\n",
    "***5. Dense()*** parameter is used to denote that the we will have regular deeply connected neural network layer.\\\n",
    "***6. Dense(50, activation='relu', input_shape=(n_cols,))) :*** Inside Dense(), \\\n",
    "$\\;\\;\\;\\;\\;\\;$**a.** *parameter* ***50*** is used to denote that a single hidden layer will have 50 units.\\\n",
    "$\\;\\;\\;\\;\\;\\;$**b.** *parameter* ***strides = (1, 1)*** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5eeb42",
   "metadata": {},
   "source": [
    "Finally, let's call the function to create the model, and then let's train it and evaluate it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05e9b4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "300/300 - 9s - loss: 0.6881 - accuracy: 0.9133 - val_loss: 0.1368 - val_accuracy: 0.9615 - 9s/epoch - 31ms/step\n",
      "Epoch 2/10\n",
      "300/300 - 8s - loss: 0.0911 - accuracy: 0.9742 - val_loss: 0.1112 - val_accuracy: 0.9684 - 8s/epoch - 28ms/step\n",
      "Epoch 3/10\n",
      "300/300 - 9s - loss: 0.0500 - accuracy: 0.9848 - val_loss: 0.0982 - val_accuracy: 0.9740 - 9s/epoch - 29ms/step\n",
      "Epoch 4/10\n",
      "300/300 - 10s - loss: 0.0322 - accuracy: 0.9899 - val_loss: 0.0983 - val_accuracy: 0.9763 - 10s/epoch - 32ms/step\n",
      "Epoch 5/10\n",
      "300/300 - 9s - loss: 0.0218 - accuracy: 0.9930 - val_loss: 0.0950 - val_accuracy: 0.9778 - 9s/epoch - 31ms/step\n",
      "Epoch 6/10\n",
      "300/300 - 9s - loss: 0.0149 - accuracy: 0.9948 - val_loss: 0.0938 - val_accuracy: 0.9801 - 9s/epoch - 31ms/step\n",
      "Epoch 7/10\n",
      "300/300 - 9s - loss: 0.0118 - accuracy: 0.9961 - val_loss: 0.0880 - val_accuracy: 0.9809 - 9s/epoch - 30ms/step\n",
      "Epoch 8/10\n",
      "300/300 - 9s - loss: 0.0159 - accuracy: 0.9945 - val_loss: 0.1180 - val_accuracy: 0.9777 - 9s/epoch - 31ms/step\n",
      "Epoch 9/10\n",
      "300/300 - 9s - loss: 0.0253 - accuracy: 0.9923 - val_loss: 0.1109 - val_accuracy: 0.9766 - 9s/epoch - 30ms/step\n",
      "Epoch 10/10\n",
      "300/300 - 9s - loss: 0.0183 - accuracy: 0.9941 - val_loss: 0.0986 - val_accuracy: 0.9789 - 9s/epoch - 30ms/step\n",
      "Accuracy: 0.9789000153541565 \n",
      " Error: 2.1099984645843506\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model = convolutional_model()\n",
    "\n",
    "# fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: {} \\n Error: {}\".format(scores[1], 100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4b7bff",
   "metadata": {},
   "source": [
    "###############################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f945b0e",
   "metadata": {},
   "source": [
    "### Convolutional NN with two sets of convolution and pooling layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4096f62",
   "metadata": {},
   "source": [
    "Let's create another convolutional model so that it has two convolutional and pooling layers instead of just one layer of each.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd568823",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_model_two():\n",
    "    \n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (5, 5), activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(8, (2, 2), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f990ec",
   "metadata": {},
   "source": [
    "Now, let's call the function to create our new convolutional neural network, and then let's train it and evaluate it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f339b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "300/300 - 11s - loss: 4.0288 - accuracy: 0.6773 - val_loss: 0.3713 - val_accuracy: 0.8973 - 11s/epoch - 38ms/step\n",
      "Epoch 2/10\n",
      "300/300 - 11s - loss: 0.2913 - accuracy: 0.9216 - val_loss: 0.2289 - val_accuracy: 0.9379 - 11s/epoch - 36ms/step\n",
      "Epoch 3/10\n",
      "300/300 - 11s - loss: 0.1893 - accuracy: 0.9473 - val_loss: 0.1668 - val_accuracy: 0.9545 - 11s/epoch - 36ms/step\n",
      "Epoch 4/10\n",
      "300/300 - 11s - loss: 0.1414 - accuracy: 0.9599 - val_loss: 0.1361 - val_accuracy: 0.9622 - 11s/epoch - 36ms/step\n",
      "Epoch 5/10\n",
      "300/300 - 11s - loss: 0.1150 - accuracy: 0.9671 - val_loss: 0.1145 - val_accuracy: 0.9655 - 11s/epoch - 36ms/step\n",
      "Epoch 6/10\n",
      "300/300 - 11s - loss: 0.0956 - accuracy: 0.9722 - val_loss: 0.1072 - val_accuracy: 0.9690 - 11s/epoch - 36ms/step\n",
      "Epoch 7/10\n",
      "300/300 - 11s - loss: 0.0830 - accuracy: 0.9759 - val_loss: 0.0963 - val_accuracy: 0.9737 - 11s/epoch - 37ms/step\n",
      "Epoch 8/10\n",
      "300/300 - 11s - loss: 0.0720 - accuracy: 0.9782 - val_loss: 0.0939 - val_accuracy: 0.9716 - 11s/epoch - 36ms/step\n",
      "Epoch 9/10\n",
      "300/300 - 11s - loss: 0.0654 - accuracy: 0.9809 - val_loss: 0.0819 - val_accuracy: 0.9769 - 11s/epoch - 36ms/step\n",
      "Epoch 10/10\n",
      "300/300 - 11s - loss: 0.0562 - accuracy: 0.9826 - val_loss: 0.0800 - val_accuracy: 0.9763 - 11s/epoch - 37ms/step\n",
      "Accuracy: 0.9763000011444092 \n",
      " Error: 2.369999885559082\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model_two = convolutional_model_two()\n",
    "\n",
    "# fit the model\n",
    "model_two.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model_two.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: {} \\n Error: {}\".format(scores[1], 100-scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
